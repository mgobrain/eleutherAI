{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scaling_laws_sweep.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5w0CZxnf8ZI3"
      },
      "source": [
        "Stella: \"So from our POV the most basic concept is the number of non-embedding params and the three ratios shown in Figure 5\"\n",
        "\n",
        "Ratios in question:\n",
        "\n",
        "(1) Feed-forward ratio (`ffr`) $\\frac{d_{ff}}{d_{model}}$\n",
        "\n",
        "(2) Aspect ratio (`ar`) $\\frac{d_{model}}{n_{layer}}$\n",
        "\n",
        "(3) Attention head dimension (`attn_dim`) $\\frac{d_{model}}{n_{head}}$\n",
        "\n",
        "Subject to:\n",
        "\n",
        "(4) $N \\approx 2d_{model}n_{layer}(2d_{attn}+d_{ff})$\n",
        "\n",
        "(5) $N = 12n_{layer}d_{model}^ 2$\n",
        "\n",
        "(6) $d_{model} = d_{attn} = d_{ff}/4$\n",
        "\n",
        "We'll focus on using (5), and using `ar` to solve for `d_model`, calculate `n_layer` using (2), then use (3) and `attn_dim` to find `n_head`.\n",
        "\n",
        "Solving (5) for `d_model` yields\n",
        "\n",
        "$d_{model} = (\\frac{\\phi N}{12})^ \\frac{1}{3}$\n",
        "\n",
        "where $\\phi$ is `ar`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o20omkC3Bdgr"
      },
      "source": [
        "! pip install wandb\n",
        "import wandb\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wa8qf8_B8akE"
      },
      "source": [
        "sweep_config = {\n",
        "    'name': 'Scaling Laws for Neural Language Models sweep',\n",
        "    'method': 'grid',\n",
        "    'metric': {\n",
        "        'name': 'loss',\n",
        "        'goal': 'minimize'\n",
        "    },\n",
        "    'parameters': {\n",
        "        'valid_set': {\n",
        "          'values': [\n",
        "                    # This will be a list of strings\n",
        "          ]\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "param_dict = {\n",
        "  # these are the ranges to sweep over\n",
        "  # ballpark numbers from Figure 5\n",
        "  'exponent': [exponent for exponent in range(10,22)],\n",
        "  'ar': [round(10**x) for x in np.linspace(1,2.5,3)],\n",
        "  'attn_dim': [round(10**x) for x in np.linspace(1.5,2.5,3)],\n",
        "}\n",
        "\n",
        "for exponent in param_dict['exponent']:\n",
        "  N = np.exp(exponent)\n",
        "  # add LR according equation D.1 from Kaplan et. al\n",
        "  # \"Scaling Laws for Neural Language Models\"\n",
        "  lr = 0.003239 + (-0.0001395)*np.log(N)\n",
        "  for ar in param_dict['ar']:\n",
        "    # substitute for n_layer, solve for d_model\n",
        "    d_model = (N*ar/12)**(1/3)\n",
        "    # calculate n_layer\n",
        "    n_layer = N/12/(d_model**2)\n",
        "    if n_layer < 1:\n",
        "      # don't clip n_layer\n",
        "      break\n",
        "    for attn_dim in param_dict['attn_dim']:\n",
        "      # add n_head per attn_dim\n",
        "      n_head = d_model/attn_dim\n",
        "      if n_head < 1:\n",
        "        # don't clip n_head\n",
        "        break\n",
        "      # add this combination as a string to sweep_config\n",
        "      sweep_config['parameters']['valid_set']['values'].append(\n",
        "          ','.join(\n",
        "              [str(round(x)) for x in \\\n",
        "               [exponent,n_layer, d_model, n_head]] + \\\n",
        "               [str(float(lr))])\n",
        "      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p54BbuZR9Str"
      },
      "source": [
        "# check config\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(\n",
        "    [[float(x) for x in y.split(',')] for y in \\\n",
        "     sweep_config['parameters']['valid_set']['values']],\n",
        "    columns=['exponent', 'n_layer', 'd_model', 'n_head', 'lr'],\n",
        "    )\n",
        "df.set_index('exponent', inplace=True)\n",
        "\n",
        "# print some examples\n",
        "for i in df.index.unique():\n",
        "  print(df.loc[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2UduwUl7JD1"
      },
      "source": [
        "def train():\n",
        "    run = wandb.init()\n",
        "    print(run.config.valid_set)\n",
        "    vars = {k:v for k,v in zip(\n",
        "        # these are from neox_arguments.md\n",
        "        ['exponent',\n",
        "         'num_layers', # \"n_layers\" (GPT)\n",
        "         'hidden_size', # \"d_model\" (GPT)\n",
        "         'num_attention_heads' # \"n_heads\" (GPT)\n",
        "         'lr' # \"learning_rate\" (GPT)\n",
        "         ],\n",
        "        [float(x) for x in run.config.valid_set.split(',')]\n",
        "    )}\n",
        "    print('Exponent (model size) {}, num_layers {}, hidden_size {}, diff(N,12*num_layers*hidden_size**2) {} percent'.format(\n",
        "        vars['exponent'], vars['num_layers'], vars['hidden_size'],\n",
        "        (np.exp(vars['exponent'])-(12*vars['num_layers']*vars['hidden_size']**2))/np.exp(vars['exponent'])*100\n",
        "    ))\n",
        "    run.finish()\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)\n",
        "agent = wandb.agent(sweep_id=sweep_id, function=train)\n",
        "agent.run()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}